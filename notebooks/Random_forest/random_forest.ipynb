{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# codecentric.AI Bootcamp - Random Forests\n",
    "\n",
    "Hallo und herzlich Willkommen beim codecentric.AI Bootcamp.\n",
    "\n",
    "Dieses Notebook enthält Beispiele und Übungsaufgaben zu Random Forests.\n",
    "Eine theoretische Einführung in Random Forests gibt es in diesem [YouTube video](https://www.youtube.com/embed/ieF_QjVUNEQ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lade Video\n",
    "from IPython.display import IFrame    \n",
    "IFrame('https://www.youtube.com/embed/ieF_QjVUNEQ', width=850, height=650)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zu diesem Notebook gibt es ebenfalls ein [Video](https://www.youtube.com/embed/7zeTynbPjkk), indem ich euch durch diese Beispiele durchführe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lade Video\n",
    "from IPython.display import IFrame    \n",
    "IFrame('https://www.youtube.com/embed/7zeTynbPjkk', width=850, height=650)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotheken\n",
    "\n",
    "Zunächst laden wir die grundlegenden Pakete, die wir für die Vorbereitung der Daten benötigten. Dazu gehören\n",
    "\n",
    "- numpy: NumPy ist das wichtigste Paket für maschinelles Lernen in Python, denn es bietet die nötigen Funktionen für die Arbeit mit Matrizen und n-dimensionalen Arrays, linearer Algebra, und mehr.\n",
    "- pandas: pandas erleichtert das Arbeiten mit Daten in Python.\n",
    "- matplotlib: Zum Erstellen von Graphiken und Abbildungen aus unseren Daten nutzen wir matplotlib. Den zusätzlichen Befehl `matplotlib inline` geben wir in unserem Juypter Notebook mit, damit wir die generierten Plots unterhalb des Code-Chunks sehen können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten einlesen und vorbereiten\n",
    "\n",
    "Random Forest ist einer von vielen Machine Learning Algorithmen des überwachten Lernens,\n",
    "im Englischen \"supervised learning\" genannt.\n",
    "\n",
    "Bei überwachtem Lernen nutzen wir sogenannte gelabelte Trainingsdaten.\n",
    "Das bedeutet, dass wir für jeden unseren Datenpunkte ein bekanntes Ergebnis als\n",
    "Zielgröße haben. Die Maschine lernt nun also dieses bekannte Ergebnis möglichst gut mit\n",
    "den vorhandenen Daten abzubilden - sie lernt quasi die optimale mathematische \n",
    "Repräsentation der Daten um mit möglichst hoher Genauigkeit auf die Zielgröße zu kommen.\n",
    "Die gelernte mathematische Repräsentation kann dann auf neue - ungelabelte - Daten\n",
    "angewandt werden und so für Vorhersagen genutzt werden.\n",
    "\n",
    "Das Scikit-learn Paket beinhaltet eine Reihe von Datensätzen, die wir direkt einladen und nutzen können. Eine Übersicht über die enthaltenen Datensätze ist hier zu finden: http://scikit-learn.org/stable/datasets/index.html\n",
    "\n",
    "Hier wollen wir einen Datensatz über Weinqualität nutzen, um zu zeigen, wie man mit Scikit-learn Random Forest Modelle trainiert. Dafür laden wir zunächst das Paket `sklearn.datasets` und daraus die `load_wine` Funktion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die `load_wine` Funktion gehört zu den \"dataset loaders\" und wird genutzt, um kleinere Datensätze (wie unseren hier) zu laden. Die `dir` Funktion zeigt uns welche Attribute unser Objekt hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'target', 'target_names']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_wine()\n",
    "dir(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Attribute können wir aufrufen, um spezielle Informationen unseres Objektes zu bekommen. Als erstes wollen wir uns die Beschreibung des Objektes und der Daten ansehen; dafür rufen wir `data.DESCR` auf und lassen es mit dem `print` Befehl ausgeben.\n",
    "\n",
    "Hier sehen wir nun, wie viele Instanzen wir haben und wie sich diese auf die Klassen verteilen, wie viele Attribute (im Machine Learning nennen wir diese Variablen auch Feature) wir haben und welche das sind. Auch über unsere Antwortvariable (auch Target, Klasse oder Label genannt) bekommen wir Informationen. Darüber hinaus erhalten wir zusammenfassende Statistiken, wie kleinste (Min) und größte (Max) Werte pro Feature, Mittelwert (Mean) und Standardabweichung (standard deviation = SD), Informationen über fehlende Werte, Klassenverteilungen und Autoren mit Veröffentlichungen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[http://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Namen der Featurespalten erhalten wir mit `data.feature_names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die tatsächlichen Daten (also die Werte für Instanzen und Feature) sind in `data.data` zu finden. Mit der `type` Funktion können wir heraus bekommen, welches Format unsere Daten haben. In diesem Fall handelt es sich um einen NumPy Array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für viele Anwendungsfälle kann es sinnvoll oder nötig sein, die Daten in ein pandas DataFrame umzuwandeln. Hier brauche wir das zwar nicht aber mit der folgenden Funktion könnten wir dies tun:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  \n",
       "0                          3.92   1065.0  \n",
       "1                          3.40   1050.0  \n",
       "2                          3.17   1185.0  \n",
       "3                          3.45   1480.0  \n",
       "4                          2.93    735.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stattdessen nutzen wir nochmal die `load_wine` Funktion, um die Daten in einem etwas anderen Format einzulesen, dass uns einen Arbeitsschritt für Scikit-learn erspart. Wenn wir `return_X_y=True` setzen, bekommen wir zwei getrennte Objekte zurück:\n",
    "\n",
    "1. Nur die Feature\n",
    "2. Nur Target/Antwortvariable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n",
      " ...\n",
      " [1.327e+01 4.280e+00 2.260e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n",
      " [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n",
      " [1.413e+01 4.100e+00 2.740e+00 ... 6.100e-01 1.600e+00 5.600e+02]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "features, target = load_wine(return_X_y=True)\n",
    "print(features)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainings- und Testsets\n",
    "\n",
    "Als nächstes wollen wir unsere Daten in Trainings- und Testsets aufteilen. Dafür gibt es in `sklearn.model_selection` die `train_test_split` Funktion. Die laden wir wieder ein und geben ihr folgende Argumente mit:\n",
    "\n",
    "- `features`: die Featurewerte\n",
    "- `target`: die Antwortvariable\n",
    "- `test_size`: wie viele der Daten in das Testset sollen (hier 30%)\n",
    "- `random_state`: Seed für die Pseudozufallsgenerierung von Nummern\n",
    "- `stratify`: optional, hier sollen Trainings- und Testset die gleichen Proportionen der Klassenverteilungen in unserer Antwortvariablen haben\n",
    "\n",
    "Mit der Hilfefunktion \"?Funktionsname\" erhalten wir Informationen über die jeweilige Funktion, ihre Argumente und Anwendungsbeispiele, z.B. `?train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                    target,\n",
    "                                                    test_size = 0.30,\n",
    "                                                    random_state = 42,\n",
    "                                                    stratify = target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Output von `train_test_split` sind vier Objekte:\n",
    "\n",
    "- `X_train`: Featurewerte für alle Trainingsinstanzen\n",
    "- `X_test`: Featurewerte für alle Testinstanzen\n",
    "- `y_train`: Label/Klassen für alle Trainingsinstanzen\n",
    "- `y_test`: Label/Klassen für alle Testinstanzen\n",
    "\n",
    "\n",
    "Wir haben nun 124 Instanzen im Trainingsset und 54 im Testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Instanzen im Trainingsset: 124\n",
      "Anzahl Instanzen im Testset: 54\n"
     ]
    }
   ],
   "source": [
    "print('Anzahl Instanzen im Trainingsset:', len(y_train))\n",
    "print('Anzahl Instanzen im Testset:',len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn\n",
    "\n",
    "[Scikit-learn](http://scikit-learn.org/stable/) ist eine Machine Learning Bibliothek für Python, die das Trainieren von vielen verschiedenen Algorithmen für Klassifikation, Regression, Clustering, und mehr sehr einfach macht. Hier wollen wir Scikit-learn nutzen, um Entscheidungsbäume und Random Forsets zu trainieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entscheidungsbäume\n",
    "\n",
    "Random Forest basiert auf Entscheidungsbäumen. Entscheidungsbäume im Machine Learning sind ebenfalls Algorithmen, die genutzt werden können, um Klassifikations- und Regressionsaufgaben zu lernen. Hier seht ihr ein Beispiel für einen einfachen Entscheidungsbaum. Wir nennen diese Methode Entscheidungs**baum** weil die gelernten Regeln mehreren \"wenn... dann...\" Entscheidungen folgen, an denen die Variablen aufgeteilt werden - ähnlich wie die Verzweigungen eines Astes.\n",
    "\n",
    "Wir starten nun also mit einem Feature, dass zum Beispiel zufällig ausgewählt wurde. Für dieses Feature wird nun anhand des gesamten Trainingsdatensatzes der optimale Grenzwert gefunden, an dem wir die Verästelung vornehmen. Wäre unser Feature zum Beispiel \"Alter\", könnte der Grenzwert bei 30 liegen. Alle Datenpunkte, die ein Alter größer als 30 haben folgen jetzt dem linken Ast, alle anderen dem rechten. Danach folgen für alle folgenden Äste weitere Verästelungen, bis wir an einem Endepunkt angekommen sind. Diese Endpunkte werden auch Blätter genannt und repräsentieren das Ergebnis - im Falle einer Klassifikationsaufgabe wäre das die vorhergesagte Klasse.\n",
    "\n",
    "Entscheidungsbäume lernen also binäre Entscheidungsregeln, die einer logischen Abfolge entsprechen. Das macht sie für uns Menschen sehr intuitiv nachvollziehbar und leicht zu verstehen.\n",
    "\n",
    "In Scikit-learn gibt es den `DecisionTreeClassifier`, mit dem wir einzelne Entscheidungsbäume trainieren können. Wir definieren dafür erst einen Learner (hier `tree` mit Default Argumenten) und wenden darauf dann die `fit` Funktion an. Die einfachste mögliche Art `fit` zu verwenden ist nur mit `X_train` (den Featuren der Trainingsdaten) und `y_train` (den Labeln/Klassen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die bisher nicht genutzen Testdaten können wir jetzt überprüfen, indem wir sie mit der `predict` Funktion klassifizieren lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese vorhergesagten Klassen können wir nun mit den tatsächlichen Klassen abgleichen, um heraus zu bekommen wie gut unser Entscheidungsbaum gelernt hat. Dafür können wir zum Bespiel eine Kreuzmatrix mit der `confusion_matrix` Funktion verwenden. Um die Darstellung schöner zu machen, konvertiere ich die Kreuzmatrix hier in ein pandas DataFrame und definiere Reihen- und Spaltennamen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred:0</th>\n",
       "      <th>pred:1</th>\n",
       "      <th>pred:2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true:0</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true:1</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true:2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred:0  pred:1  pred:2\n",
       "true:0      17       1       0\n",
       "true:1       2      19       0\n",
       "true:2       0       0      15"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "unique_label = np.unique(y_test)\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred, labels=unique_label), \n",
    "                   index=['true:{:}'.format(x) for x in unique_label], \n",
    "                   columns=['pred:{:}'.format(x) for x in unique_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einzelne Entscheidungsbäume sind allerdings nicht sehr robust und führen sehr leicht zu Overfitting. Das bedeutet, dass sie zwar die mathematischen Regeln für einen Trainingsdatensatz sehr genau lernen können, sie sind aber häufig nicht in der Lage allgemeingültige Regeln abzuleiten, die auf neue Daten angewandt werden können.\n",
    "Random Forests sind hier besser, denn sie basieren auf den gesammelten Vorhersagen von vielen Entscheidungsbäumen.\n",
    "\n",
    "Einfach dargestellt, werden viele verschiedene Entscheidungsbäume auf dem selben Trainingsdatensatz berechnet. Das Endergebnis ergibt sich dann aus den Ergebnissen der einzelnen Bäume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "\n",
    "Was Random Forests besser macht sind vor allem zwei Tricks: zum einen wird bei jeder Verästelung nur eine zufällige Teilmenge der Feature in Betracht gezogen. Das hilft, den Einfluss von stark korrelierten Featuren zu verringern. Der zweite Trick besteht darin, wie die Ergebnisse der einzelnen Entscheidungsbäume zu einem gemeinsamen Endergebnis kombiniert werden.\n",
    "\n",
    "Im Wesentlichen gibt es zwei Methoden, um Entscheidungsbäume zu kombinieren. Das ist einmal das sogenannten Bagging oder Bootstrap Aggregierung. Bei dieser Methode werden zufällige Teilmengen der Daten genommen, um die einzelnen Bäume zu trainieren. Dabei kann das Sampling der Daten mit oder ohne Zurücklegen passieren. Ein großer Vorteil dieser Methode ist, dass die einzelnen Entscheidungsbäume parallel trainiert werden können, so dass diese Methode sehr schnell und effektiv ist. Bei Random Forest wird in der Regel die Bagging-Methode verwendet.\n",
    "Das Endergebnis ergibt sich dann entweder aus dem Durchschnitt der Ergebnisse der einzelnen Bäume oder wird durch Mehrheitsvotum bestimmt.\n",
    "\n",
    "In Scikit-learn gibt es den `BaggingClassifier`,  mit dem wir eine Anzahl von Entscheidungsbäumen trainieren und mit der Baggingmethode kombinieren können. Dafür geben wir der Funktion ein paar Hyperparameter mit:\n",
    "\n",
    "- `base_estimator`: definiert die Entscheidungsbäume, die genutzt werden sollen (hier der Default `DecisionTreeClassifier` von oben)\n",
    "- `n_estimators`: Anzahl der zu kombinierenden Bäume\n",
    "- `max_samples`: Anzahl der Instanzen, die für das Training der einzelnen Entscheidungsbäume zufällig aus dem Trainingsset gesampelt werden sollen (hier 80%)\n",
    "\n",
    "Außerdem definieren wir wieder einen Random Seed `random_state`. Zusätzliche Argumente und Hyperparameter sind in der Hilfe gelistet (aufzurufen mit `?BaggingClassifier`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "         max_samples=0.8, n_estimators=100, n_jobs=None, oob_score=False,\n",
       "         random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag = BaggingClassifier(base_estimator = tree, \n",
    "                        n_estimators = 100, \n",
    "                        max_samples = 0.8, \n",
    "                        random_state = 42)\n",
    "bag.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses trainierte Modell kann wieder für Vorhersagen auf neuen oder Testdaten verwendet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred:0</th>\n",
       "      <th>pred:1</th>\n",
       "      <th>pred:2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true:0</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true:1</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true:2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred:0  pred:1  pred:2\n",
       "true:0      18       0       0\n",
       "true:1       0      21       0\n",
       "true:2       0       0      15"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_bag = bag.predict(X_test)\n",
    "\n",
    "unique_label = np.unique(y_test)\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred_bag, labels=unique_label), \n",
    "                   index=['true:{:}'.format(x) for x in unique_label], \n",
    "                   columns=['pred:{:}'.format(x) for x in unique_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests\n",
    "\n",
    "Mit Scikit-learn können wir auch sehr einfach Klassifikations- und Regressionsmodelle direkt mit dem Random Forest Algorithmus trainieren. \n",
    "\n",
    "Die Vorteile von Random Forests sind vor allem die Schnelligkeit, weil das Training parallelisiert durchgeführt werden kann. Viele Aufgaben können mit Random Forests mit recht guter Genauigkeit gelöst werden, so dass wir recht flexibel mit diesem Algorithmus sind. Außerdem bekommen wir als Ergebnis Vorhersagewahrscheinlichkeiten, die uns helfen die Ergebnisse besser einzuschätzen.\n",
    "\n",
    "Nachteile sind vor allem, dass Random Forests zum Overfitting neigen und vor allem bei stark unbalancierten Daten Probleme haben, die unterrepräsentierte Klasse zu lernen. Und - wie die meisten anderen Machine Learning Algorithmen auch - sind Random Forests Blackbox-Modelle, das heißt, die Entscheidungen sind nicht mehr im Detail nachzuvollziehen.\n",
    "\n",
    "Je nachdem ob unser bekanntes Ergebnis einer Einteilung in Gruppen, bzw. Klassen entspricht\n",
    "oder die Zielgröße kontinuierliche Werte darstellen, sprechen wir von Klassifikation\n",
    "oder Regression. Random Forest kann für beides genutzt werden.\n",
    "\n",
    "#### Klassifikation\n",
    "\n",
    "Wenn wir mit Scikit-learn eine Klassifikation durchführen wollen, können wir den `RandomForestClassifier` verwenden. Das Prinzp folgt analog zum `DecisionTreeClassifier` und `BaggingClassifier` von oben:\n",
    "\n",
    "1. Definition des Algorithmus (hier `RandomForestClassifier` mit Anzahl zu trainierender Bäume)\n",
    "2. Trainieren des Modell mit `fit`\n",
    "3. Evaluieren auf Testdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für das Vorhersagen von neuen Daten können wir wieder wie zuvor die `predict` Funktion mit `confusion_matrix` verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred:0</th>\n",
       "      <th>pred:1</th>\n",
       "      <th>pred:2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true:0</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true:1</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true:2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred:0  pred:1  pred:2\n",
       "true:0      18       0       0\n",
       "true:1       0      21       0\n",
       "true:2       0       0      15"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "unique_label = np.unique(y_test)\n",
    "pd.DataFrame(confusion_matrix(y_test, y_pred_rf, labels=unique_label), \n",
    "                   index=['true:{:}'.format(x) for x in unique_label], \n",
    "                   columns=['pred:{:}'.format(x) for x in unique_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per Default gibt uns die `predict` Funktion Klassenlabel aus, wir können uns aber auch Vorhersagewahrscheinlichkeiten ausgeben lassen. Dafür gibt es die `predict_proba` Funktion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95, 0.03, 0.02],\n",
       "       [0.01, 0.97, 0.02],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [0.98, 0.02, 0.  ],\n",
       "       [0.81, 0.19, 0.  ],\n",
       "       [0.98, 0.02, 0.  ],\n",
       "       [0.01, 0.04, 0.95],\n",
       "       [0.  , 1.  , 0.  ],\n",
       "       [0.24, 0.67, 0.09],\n",
       "       [0.06, 0.23, 0.71]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.predict_proba(X_test)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weitere Möglichkeiten, um die Performance eines Modells in Scikit-learn zu bewerten sind [hier](http://scikit-learn.org/stable/modules/model_evaluation.html) aufgezählt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression\n",
    "\n",
    "Der Weindatensatz ist eigentlich für Klassifikationsprobleme gedacht, denn wir wollen die Weinqualität in eine von drei möglichen Klassen eingeteilt vorhersagen. Unser Antwortvariable ist also kategorisch.\n",
    "\n",
    "Wir könnten Random Forests aber auch verwenden, wenn unsere Antwortvariable numerisch wäre - wir würden dann keine Klassen, sondern numerische Werte vorhersagen. Dafür würden wir den `RandomForestRegressor` verwenden. Die Random Forest Funktionen `RandomForestClassifier` und `RandomForestRegressor` konvertieren die Antwortvariable `y_train` automatisch in das entsprechende Format.\n",
    "\n",
    "Die `predict` Funktion gibt bei einem Regressionsmodell dann entprechend numerische Werte zurück."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.   1.   0.   0.   0.07 0.   2.   1.   0.96 1.86 1.45 0.95 1.99 0.99\n",
      " 0.   2.   0.97 0.55 1.8  1.98 1.01 1.83 1.98 1.67 1.09 2.   0.02 0.73\n",
      " 0.   0.88 0.69 0.86 1.9  0.99 0.96 2.   1.11 1.03 1.02 0.2  1.98 0.\n",
      " 0.   0.   0.   1.08 1.   0.   1.95 0.27 1.01 1.02 2.   0.  ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_reg_model = RandomForestRegressor(n_estimators = 100, random_state = 42)\n",
    "rf_reg_model.fit(X_train, y_train)\n",
    "y_pred_rf_reg = rf_reg_model.predict(X_test)\n",
    "print(y_pred_rf_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anstelle von Kreuzmatrizen können wir für Regressionsmodelle andere Metriken verwenden, z.B. den mittleren Fehler oder die Wurzel daraus, den Logloss, absoluten Fehler oder andere. Eine Liste ist [hier](http://scikit-learn.org/stable/modules/model_evaluation.html) zu finden.\n",
    "\n",
    "Hier verwenden wir z.B. den mittleren Fehler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02690185185185185"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_test, y_pred_rf_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können Vorhersage gegen Wirklichkeit auch graphisch darstellen, z.B. als Scatterplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fbcfda26710>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, y_pred_rf_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können uns auch einzelne Entscheidungsbäume als Baum darstellen lassen. Dafür gibt es die `export_graphviz` Funktion und das pydot Paket.\n",
    "\n",
    "Mit `rf_reg_model.estimators_[index]` können wir einzelne Bäume unseres Modell extrahieren und als .dot Datei exportieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "\n",
    "# 5. Baum extrahieren\n",
    "tree_est = rf_reg_model.estimators_[5]\n",
    "\n",
    "# In .dot exportieren\n",
    "export_graphviz(tree_est, out_file = 'tree.dot', feature_names = data.feature_names, rounded = True, precision = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese .dot Datei können wir z.B. auf http://www.webgraphviz.com/ visualisieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H2O\n",
    "\n",
    "[H2O](https://www.h2o.ai/) ist eine beliebte Open-Source Machine Learning Plattform, mit der man ebenfalls sehr einfach und schnell Random Forests trainieren und tunen kann.\n",
    "\n",
    "Im Unterschied zu Scikit-learn läuft H2O auf Clustern mit einem Java Backend. Wir können unser Cluster lokal starten oder z.B. mit Spark, Hadoop oder anderen Umgebungen. Je nachdem, wie rechenintensiv unsere Modelle sind, können wir durch das Nutzen von mehreren Clustern und Knoten eine deutlich schnellere Trainingszeit erreichen als mit Scikit-learn.\n",
    "\n",
    "Zunächst importieren wir die h2o Bibliothek und starten das Cluster. Mit `nthreads = -1` werden alle Kerne einer Machine genutzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"1.8.0_181\"; OpenJDK Runtime Environment (build 1.8.0_181-8u181-b13-1~deb9u1-b13); OpenJDK 64-Bit Server VM (build 25.181-b13, mixed mode)\n",
      "  Starting server from /usr/local/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmp1nf3wz62\n",
      "  JVM stdout: /tmp/tmp1nf3wz62/h2o_unknownUser_started_from_python.out\n",
      "  JVM stderr: /tmp/tmp1nf3wz62/h2o_unknownUser_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>03 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.20.0.8</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 month and 23 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_unknownUser_7uaudp</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>444.5 Mb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.6 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         03 secs\n",
       "H2O cluster timezone:       Etc/UTC\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.20.0.8\n",
       "H2O cluster version age:    1 month and 23 days\n",
       "H2O cluster name:           H2O_from_python_unknownUser_7uaudp\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    444.5 Mb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.6 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init(nthreads = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In h2o gibt es auch wieder [mehrere Algorithmen](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science.html), die zum Trainieren von Modellen genutzt werden können. Für h2o ist das die `H2ORandomForestEstimator` Funktion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.random_forest import H2ORandomForestEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses Mal starten wir mit dem pandas DataFrame `df`, das wir zu Anfang aus dem numpy Array generiert haben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  \n",
       "0                          3.92   1065.0  \n",
       "1                          3.40   1050.0  \n",
       "2                          3.17   1185.0  \n",
       "3                          3.45   1480.0  \n",
       "4                          2.93    735.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses DataFrame enthält bisher nur die Feature, darum kombiniere ich es hier mit der Antwortvariablen, indem ich diese ebenfalls in ein pandas DataFrame schreibe und die Spalten dieser beiden DataFrame mit `pd.concat` verbinde. Die erste Spalte `class` enthält jetzt also die vorherzusagenden Klassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  \\\n",
       "0      0    14.23        1.71  2.43               15.6      127.0   \n",
       "1      0    13.20        1.78  2.14               11.2      100.0   \n",
       "2      0    13.16        2.36  2.67               18.6      101.0   \n",
       "3      0    14.37        1.95  2.50               16.8      113.0   \n",
       "4      0    13.24        2.59  2.87               21.0      118.0   \n",
       "\n",
       "   total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   color_intensity   hue  od280/od315_of_diluted_wines  proline  \n",
       "0             5.64  1.04                          3.92   1065.0  \n",
       "1             4.38  1.05                          3.40   1050.0  \n",
       "2             5.68  1.03                          3.17   1185.0  \n",
       "3             7.80  0.86                          3.45   1480.0  \n",
       "4             4.32  1.04                          2.93    735.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.DataFrame({'class':data.target})\n",
    "\n",
    "df_c = pd.concat([target, df], axis=1)\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bevor wir mit h2o arbeiten können, müssen wir unsere Daten in ein H2O Frame konvertieren. Dafür gibt es die `h2o.H2OFrame` Funktion. Unsere Antwortvariable ist im Moment noch numerisch, h2o würde also eine Regression durchführen. Wir wollen aber eine Klassifikation trainieren, darum konvertiere ich die Variable mit `asfactor`. Mit `describe` bekommen wir eine umfangreiche Beschreibung der Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h2o/utils/shared_utils.py:177: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  data = _handle_python_lists(python_obj.as_matrix().tolist(), -1)[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf = h2o.H2OFrame(df_c)\n",
    "hf[0] = hf[0].asfactor()  \n",
    "hf[0].isfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:178\n",
      "Cols:14\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>class  </th><th>alcohol           </th><th>malic_acid        </th><th>ash                </th><th>alcalinity_of_ash  </th><th>magnesium         </th><th>total_phenols     </th><th>flavanoids        </th><th>nonflavanoid_phenols  </th><th>proanthocyanins   </th><th>color_intensity  </th><th>hue                </th><th>od280/od315_of_diluted_wines  </th><th>proline          </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>enum   </td><td>real              </td><td>real              </td><td>real               </td><td>real               </td><td>int               </td><td>real              </td><td>real              </td><td>real                  </td><td>real              </td><td>real             </td><td>real               </td><td>real                          </td><td>int              </td></tr>\n",
       "<tr><td>mins   </td><td>       </td><td>11.03             </td><td>0.74              </td><td>1.36               </td><td>10.6               </td><td>70.0              </td><td>0.98              </td><td>0.34              </td><td>0.13                  </td><td>0.41              </td><td>1.28             </td><td>0.48               </td><td>1.27                          </td><td>278.0            </td></tr>\n",
       "<tr><td>mean   </td><td>       </td><td>13.000617977528085</td><td>2.336348314606743 </td><td>2.366516853932584  </td><td>19.494943820224723 </td><td>99.74157303370781 </td><td>2.295112359550562 </td><td>2.0292696629213474</td><td>0.36185393258426946   </td><td>1.5908988764044947</td><td>5.058089882022471</td><td>0.9574494382022474 </td><td>2.6116853932584254            </td><td>746.8932584269659</td></tr>\n",
       "<tr><td>maxs   </td><td>       </td><td>14.83             </td><td>5.8               </td><td>3.23               </td><td>30.0               </td><td>162.0             </td><td>3.88              </td><td>5.08              </td><td>0.66                  </td><td>3.58              </td><td>13.0             </td><td>1.71               </td><td>4.0                           </td><td>1680.0           </td></tr>\n",
       "<tr><td>sigma  </td><td>       </td><td>0.811826538005858 </td><td>1.1171460976144625</td><td>0.27434400906081485</td><td>3.339563767173504  </td><td>14.282483515295652</td><td>0.6258510488339892</td><td>0.9988586850169471</td><td>0.12445334029667941   </td><td>0.5723588626747612</td><td>2.318285871822413</td><td>0.22857156582982327</td><td>0.7099904287650503            </td><td>314.9074742768492</td></tr>\n",
       "<tr><td>zeros  </td><td>       </td><td>0                 </td><td>0                 </td><td>0                  </td><td>0                  </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                     </td><td>0                 </td><td>0                </td><td>0                  </td><td>0                             </td><td>0                </td></tr>\n",
       "<tr><td>missing</td><td>0      </td><td>0                 </td><td>0                 </td><td>0                  </td><td>0                  </td><td>0                 </td><td>0                 </td><td>0                 </td><td>0                     </td><td>0                 </td><td>0                </td><td>0                  </td><td>0                             </td><td>0                </td></tr>\n",
       "<tr><td>0      </td><td>0      </td><td>14.23             </td><td>1.71              </td><td>2.43               </td><td>15.6               </td><td>127.0             </td><td>2.8               </td><td>3.06              </td><td>0.28                  </td><td>2.29              </td><td>5.64             </td><td>1.04               </td><td>3.92                          </td><td>1065.0           </td></tr>\n",
       "<tr><td>1      </td><td>0      </td><td>13.2              </td><td>1.78              </td><td>2.14               </td><td>11.2               </td><td>100.0             </td><td>2.65              </td><td>2.76              </td><td>0.26                  </td><td>1.28              </td><td>4.38             </td><td>1.05               </td><td>3.4                           </td><td>1050.0           </td></tr>\n",
       "<tr><td>2      </td><td>0      </td><td>13.16             </td><td>2.36              </td><td>2.67               </td><td>18.6               </td><td>101.0             </td><td>2.8               </td><td>3.24              </td><td>0.3                   </td><td>2.81              </td><td>5.68             </td><td>1.03               </td><td>3.17                          </td><td>1185.0           </td></tr>\n",
       "<tr><td>3      </td><td>0      </td><td>14.37             </td><td>1.95              </td><td>2.5                </td><td>16.8               </td><td>113.0             </td><td>3.85              </td><td>3.49              </td><td>0.24                  </td><td>2.18              </td><td>7.8              </td><td>0.86               </td><td>3.45                          </td><td>1480.0           </td></tr>\n",
       "<tr><td>4      </td><td>0      </td><td>13.24             </td><td>2.59              </td><td>2.87               </td><td>21.0               </td><td>118.0             </td><td>2.8               </td><td>2.69              </td><td>0.39                  </td><td>1.82              </td><td>4.32             </td><td>1.04               </td><td>2.93                          </td><td>735.0            </td></tr>\n",
       "<tr><td>5      </td><td>0      </td><td>14.2              </td><td>1.76              </td><td>2.45               </td><td>15.2               </td><td>112.0             </td><td>3.27              </td><td>3.39              </td><td>0.34                  </td><td>1.97              </td><td>6.75             </td><td>1.05               </td><td>2.85                          </td><td>1450.0           </td></tr>\n",
       "<tr><td>6      </td><td>0      </td><td>14.39             </td><td>1.87              </td><td>2.45               </td><td>14.6               </td><td>96.0              </td><td>2.5               </td><td>2.52              </td><td>0.3                   </td><td>1.98              </td><td>5.25             </td><td>1.02               </td><td>3.58                          </td><td>1290.0           </td></tr>\n",
       "<tr><td>7      </td><td>0      </td><td>14.06             </td><td>2.15              </td><td>2.61               </td><td>17.6               </td><td>121.0             </td><td>2.6               </td><td>2.51              </td><td>0.31                  </td><td>1.25              </td><td>5.05             </td><td>1.06               </td><td>3.58                          </td><td>1295.0           </td></tr>\n",
       "<tr><td>8      </td><td>0      </td><td>14.83             </td><td>1.64              </td><td>2.17               </td><td>14.0               </td><td>97.0              </td><td>2.8               </td><td>2.98              </td><td>0.29                  </td><td>1.98              </td><td>5.2              </td><td>1.08               </td><td>2.85                          </td><td>1045.0           </td></tr>\n",
       "<tr><td>9      </td><td>0      </td><td>13.86             </td><td>1.35              </td><td>2.27               </td><td>16.0               </td><td>98.0              </td><td>2.98              </td><td>3.15              </td><td>0.22                  </td><td>1.85              </td><td>7.22             </td><td>1.01               </td><td>3.55                          </td><td>1045.0           </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch in h2o können wir unsere Daten sehr einfach in Trainings- und Testsets einteilen. Zu Demonstrationszwecken teile ich die Daten hier in drei Sets ein: Training, Validierung und Test. Bei der geringen Anzahl an Instanzen ist das aber eigentlich nicht sinnvoll - wir würden stattdessen Kreuzvalidierung verwenden.\n",
    "\n",
    "Die `split_frame` Funktion bekommt einen Vektor von Werten zwischen 0 und 1, die in Summe weniger als 1 sein müssen. Diese Werte stellen den Anteil der Daten für das Trainingsset (hier 70%), das Validierungsset (hier 15%) und das Testset (die verbleibenden 15%) dar. Die drei Datensets bekommen wir als separate Objekte zurück."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = hf.split_frame([0.7, 0.15], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zur Vorbereitung definieren wir nun auch noch einen Vektor mit allen Featurenamen (Spaltennamen), die wir zum Trainieren verwenden wollen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_X = hf.col_names[1:len(hf.col_names)]\n",
    "hf_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Außerdem generieren wir noch einen mit der Antwortvariablen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_y = hf.col_names[0]\n",
    "hf_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können wir den `H2ORandomForestEstimator` definieren. Weitere Hyperparameter sind in der Funktionsbeschreibung unter http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/drf.html gelistet. Wenn wir in diese Liste gucken, sehen wir direkt, dass wir eine ganze Menge an Hyperparametern und zusätzlichen Optionen wählen können. Hier wählen wir ein paar:\n",
    "\n",
    "- `ntrees`: Anzahl Entscheidungsbäume\n",
    "- `max_depth`: Maximale Baumtiefe\n",
    "- `min_rows`: Minimale Anzahl an Instanzen pro Blatt\n",
    "\n",
    "Außerdem geben wir der Funktion noch Stopp-Kriterien mit, die angeben, wann das Training abgebrochen werden soll. Hier wollen wir das Training unterbrechen, wenn der mittlere Fehler pro Klasse `mean_per_class_error` 3x hintereinander nicht mindestens um 0.001 besser wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = H2ORandomForestEstimator(\n",
    "    ntrees = 200,\n",
    "    max_depth = 3,\n",
    "    min_rows = 5,\n",
    "    stopping_rounds = 3,\n",
    "    stopping_metric = 'mean_per_class_error',\n",
    "    stopping_tolerance = 1e-3,\n",
    "    seed = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit `train` erfolgt dann das eigentliche Traineren des Modells. Wenn wir mit einem Validierungsset arbeiten, wie hier, geben wir dieses neben dem Trainingsset an. Falls wir kein Validierungsset hätten und Kreuzvalidierung durchführen wollten, würden wir statt `validation_frame` die Argumente `nfolds` (Anzahl Folds) im H2ORandomForestEstimator setzen. Die Namen der Spalten für Feature und Antwortvariablen geben wir mit `x` und `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "rf.train(x = hf_X, \n",
    "         y = hf_y, \n",
    "         training_frame = train, \n",
    "         validation_frame = valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbilden können wir die Entwicklung mehrerer Performance-Metriken auf Validierungsdaten über die Trainingszyklen mit `score_history` und matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbcfb2f22e8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sh = rf.score_history()\n",
    "sh.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine Übersicht über die Performance unseres Modells auf den Testdaten erhalten wir mit der `model_performance` Funktion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: drf\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.0595180965487881\n",
      "RMSE: 0.24396330984143516\n",
      "LogLoss: 0.23992978191902167\n",
      "Mean Per-Class Error: 0.0\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>9.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 9</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>10.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 10</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 5</td></tr>\n",
       "<tr><td>9.0</td>\n",
       "<td>10.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 24</td></tr></table></div>"
      ],
      "text/plain": [
       "0    1    2    Error    Rate\n",
       "---  ---  ---  -------  ------\n",
       "9    0    0    0        0 / 9\n",
       "0    10   0    0        0 / 10\n",
       "0    0    5    0        0 / 5\n",
       "9    10   5    0        0 / 24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    1\n",
       "2    1\n",
       "3    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "performance = rf.model_performance(test_data=test)\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vorhersagen auf Testdaten erhalten wir wieder mit der `predict` Funktion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">       p0</th><th style=\"text-align: right;\">       p1</th><th style=\"text-align: right;\">         p2</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.942857 </td><td style=\"text-align: right;\">0.0560262</td><td style=\"text-align: right;\">0.00111662 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.801387 </td><td style=\"text-align: right;\">0.0347439</td><td style=\"text-align: right;\">0.163869   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.624113 </td><td style=\"text-align: right;\">0.375165 </td><td style=\"text-align: right;\">0.000721843</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.502701 </td><td style=\"text-align: right;\">0.496356 </td><td style=\"text-align: right;\">0.000942644</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.942857 </td><td style=\"text-align: right;\">0.0560262</td><td style=\"text-align: right;\">0.00111662 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.624143 </td><td style=\"text-align: right;\">0.37516  </td><td style=\"text-align: right;\">0.00069741 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.841725 </td><td style=\"text-align: right;\">0.0490624</td><td style=\"text-align: right;\">0.109213   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.925722 </td><td style=\"text-align: right;\">0.0537214</td><td style=\"text-align: right;\">0.0205571  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.84373  </td><td style=\"text-align: right;\">0.155242 </td><td style=\"text-align: right;\">0.00102766 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.0741453</td><td style=\"text-align: right;\">0.916943 </td><td style=\"text-align: right;\">0.00891169 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
